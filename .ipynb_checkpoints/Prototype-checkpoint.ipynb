{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#local lib\n",
    "sys.path.insert(0, os.path.abspath('../KindScoreModel'))\n",
    "import KindScore as ks\n",
    "import SpeechRecognition as sr\n",
    "\n",
    "# from KindScore import Speechtext as kss\n",
    "# from KindScore import Weightscore as ksws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dataReV5.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, model = ks.KindScoreModel(df,\"Problem\",\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemList =  []\n",
    "problemList.append(sr.FileRecognition(\"C:/Users/Pack.Apichart/Desktop/Re_project/Cluster_speech_two/data/sound/01.wav\",15))\n",
    "problemList.append(sr.FileRecognition(\"C:/Users/Pack.Apichart/Desktop/Re_project/Cluster_speech_two/data/sound/02.wav\",15))\n",
    "problemList.append(sr.FileRecognition(\"C:/Users/Pack.Apichart/Desktop/Re_project/Cluster_speech_two/data/sound/03.wav\",15))\n",
    "problemList.append(sr.FileRecognition(\"C:/Users/Pack.Apichart/Desktop/Re_project/Cluster_speech_two/data/sound/04.wav\",15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech = str(ks.Speechtext())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # speech_list = []\n",
    "# l = []\n",
    "# group_text = []\n",
    "# # speech_list.append(speech)\n",
    "\n",
    "\n",
    "# for y in speech_list:\n",
    "#     l.append(ks.sentence_vectorizer(y)[0])\n",
    "# KL=np.array(l)\n",
    "# labels_newProblem = model.predict(KL)\n",
    "# group_text.append(labels_newProblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE New problem to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weightscore(path : str, sentence, dataset,model, problem: str, score : str):\n",
    "    text = sentence\n",
    "    pathFile = path+'.csv'\n",
    "    cluster = []\n",
    "    l = []\n",
    "    \n",
    "    for word in text:\n",
    "        l.append(ks.sentence_vectorizer(word)[0])\n",
    "    KL=np.array(l)\n",
    "    \n",
    "    newProblem = model.predict(KL)\n",
    "    cluster.append(newProblem)\n",
    "    \n",
    "    for countgroup in range(len(newProblem)):\n",
    "        state_score = \"\"\n",
    "        state_similarity = 0\n",
    "        print(countgroup)\n",
    "        for index in dataset[dataset['cluster'] == newProblem[countgroup]].values:\n",
    "            \n",
    "            check_similarity = ks.sentence_similarity(text[countgroup], index[0])\n",
    "            if(check_similarity > state_similarity):\n",
    "                state_similarity = check_similarity\n",
    "                state_score = index[1]\n",
    "        \n",
    "            \n",
    "        dataset.loc[dataset.shape[0]]= [text[countgroup],state_score,newProblem[countgroup]];\n",
    "\n",
    "        print(text[countgroup], \"group: \", newProblem[countgroup], \"similarity: \" ,state_similarity[0][0], \"score :\" , state_score)\n",
    "\n",
    "#     with open(pathFile, 'a', encoding=\"utf-8\") as f:\n",
    "#          dataset.to_csv(f, header=False)\n",
    "    dataset.to_csv(path+\".csv\", mode='a', header=True, index=False, encoding=\"utf-8\")\n",
    "#         new_df.to_csv(path+\".csv\", mode='a', header=False, index=False)\n",
    "#             dataset.loc[69]= [text[countgroup],state_score,newProblem[countgroup]]\n",
    "\n",
    "\n",
    "    return print(\"write result to path :\",pathFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Weightscore(\"data/dataReV656\",problemList,data,model,\"Problem\",\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dataReV656.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/dataReV656.csv\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "สวัสดีครับ ผมเป็นนักึกษาชั้นปีที่ 3 คณะเทคโนโลยีสารสนเทศ สถาบันเทคโนโลยีพระจอมเกล้าเจ้าคุณทหารลาดกระบัง\n",
    "วิชา SOFTWARE VERIFICATION AND VALIDATION \n",
    "ซึงให้ทดสอบเว็บไซต์ทางกลุ่มจึงเลือกทดสอบเว็บไซต์ของทาง thepaseomall และ thepaseotown\n",
    "และมีผลการทดสอบตามไฟล์ข้อมูลที่ได้แนบไปครับ \n",
    "โดยมีการส่งสองช่องทางคือ ทางอีเมล์ kpn_lkb1158@hotmail.com และทางช่องสนทนาของเพจ @thepaseomall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
