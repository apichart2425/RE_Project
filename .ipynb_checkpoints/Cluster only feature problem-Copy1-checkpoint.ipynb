{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pythainlp import word_tokenize\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# from pythainlp.word_vector import thai2vec \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "from pythainlp.tokenize import word_tokenize,sent_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from scipy.cluster import hierarchy\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "import pythainlp.word_vector\n",
    "# model = word_vector.get_model()\n",
    "model_path = 'thwiki_data/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dataReV5.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Problem'].dropna()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp import word_tokenize, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_newmm= []\n",
    "sentences_longest= []\n",
    "\n",
    "for x in text:\n",
    "    proc_newmm = word_tokenize(x, engine='newmm', keep_whitespace=False)\n",
    "    proc_longest = word_tokenize(x, engine='longest', keep_whitespace=False)\n",
    "\n",
    "    lst_newmm = []\n",
    "    lst_longest = []\n",
    "    \n",
    "    for word in proc_newmm:\n",
    "        if(word != \" \"):\n",
    "            lst_newmm.append(word)\n",
    "    sentences_newmm.append(lst_newmm)\n",
    "    for word in proc_longest:\n",
    "        if(word != \" \"):\n",
    "            lst_longest.append(word)\n",
    "    sentences_longest.append(lst_longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nlp = pythainlp.word_vector.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vectorizer(ss,dim=300,use_mean=True): # ประกาศฟังก์ชัน sentence_vectorizer\n",
    "    s = word_tokenize(ss)\n",
    "    vec = np.zeros((1,dim))\n",
    "    for word in s:\n",
    "        if word in model_nlp.wv.index2word: \n",
    "            vec+= model_nlp.wv.word_vec(word)\n",
    "        else: pass\n",
    "    if use_mean: vec /= len(s)\n",
    "    return vec\n",
    "\n",
    "lst_vector = []\n",
    "for i in text:\n",
    "    lst_vector.append(sentence_vectorizer(i)[0])\n",
    "X=np.array(lst_vector)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow=elbow_point(wcss)\n",
    "elbow.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(wcss)+1\n",
    "K= range(1, n)\n",
    "\n",
    "print(\"Optimal Cluster Number: \",K[elbow])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(K, wcss, 'bx-')\n",
    "ax.plot(K[elbow], wcss[elbow], marker='o', markersize=12,markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "# ax.set_xticks(np.arange(0,n,1))\n",
    "# ax.set_yticks(np.arange(0,max(wcss),0.5))\n",
    "plt.grid()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average within-cluster sum of squares')\n",
    "plt.title('Elow for KMeans clustering')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = K[elbow]\n",
    "clf = KMeans(n_clusters=n_clusters,\n",
    "            max_iter=100,\n",
    "            init='k-means++',\n",
    "            n_init=1)\n",
    "labels = clf.fit_predict(X)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "clf = KMeans(n_clusters=n_clusters,\n",
    "            max_iter=100,\n",
    "            init='k-means++',\n",
    "            n_init=1)\n",
    "labels = clf.fit_predict(X)\n",
    "labels\n",
    "cluster = []\n",
    "value = []\n",
    "o = \"\"\n",
    "for index, sentence in enumerate(sentences_newmm):\n",
    "#     print(str(labels[index]) + \":\" + str(sentence))\n",
    "    cluster.append(labels[index])\n",
    "    value.append(o.join(sentences_newmm[index]))\n",
    "list_of_cluster = list(zip(cluster,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.DataFrame(list_of_cluster, columns = ['cluster', 'text'])  \n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
